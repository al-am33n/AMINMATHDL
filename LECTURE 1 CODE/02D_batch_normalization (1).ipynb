{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0h3cSU6ZGO_"
      },
      "source": [
        "# Batch Normalization on CIFAR-10\n",
        "\n",
        "In this notebook we implement batch normalization, which is an opimization method useful for deep feed-forward neural networks, such as deep CNNs. Here we implement it on a toy-model of fully-connected (dense) layers, and toy-data (CIFAR-10).\n",
        "\n",
        "In addition to Batch Normalization, we demonstrate how to implement early stopping, saving a checkpoint model, and use Keras logging for Tensorboard.\n",
        "\n",
        "The main takeaways from this notebook are to know how to implement in Keras:\n",
        "1. Batch Normalization\n",
        "2. Early Stopping\n",
        "3. Saving Checkpoints\n",
        "4. Default Keras Logs into Tensorboard\n",
        "\n",
        "Based on the [notebook](https://github.com/ageron/handson-ml3/blob/main/11_training_deep_neural_networks.ipynb) of Geron, chapter 11, exercise 8.\n",
        "Presented here in accordance with the Apache 2.0 license."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYLpIvJtZGPC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU9uGOujZGPD"
      },
      "source": [
        "## Get the Data\n",
        "CIFAR-10 dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes (for students: what is the difference between CIFAR-10 and MNIST in that sense?).\n",
        "\n",
        "We get the data from tf.keras.datasets (similar to how we did for MNIST). This means that we get numpy array back.\n",
        "\n",
        "As seen in the [dataset description](https://keras.io/api/datasets/cifar10/), the 10 classes are:\n",
        "\n",
        "Label |\tDescription\n",
        "--- | ---\n",
        "0 |\tairplane\n",
        "1 |\tautomobile\n",
        "2 |\tbird\n",
        "3 |\tcat\n",
        "4 |\tdeer\n",
        "5 |\tdog\n",
        "6 |\tfrog\n",
        "7 |\thorse\n",
        "8 |\tship\n",
        "9 |\ttruck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0749QQ7ZGPE"
      },
      "outputs": [],
      "source": [
        "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
        "\n",
        "# TODO: for the students: how many images are there in the training and the validation sets?\n",
        "# TODO: for the students: what does 'x' and 'y' stand for?\n",
        "X_train = X_train_full[5000:]\n",
        "y_train = y_train_full[5000:]\n",
        "X_valid = X_train_full[:5000]\n",
        "y_valid = y_train_full[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKkN_oRZGPE"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWXWXWRmZGPE",
        "outputId": "7d6e2801-2263-49d5-aeaa-c3069b512afc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x234b7c45410>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1aS1FhiZGPF",
        "outputId": "c64db814-31f7-4d65-cd70-fc777284a5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6]\n"
          ]
        }
      ],
      "source": [
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3mx8qf1ZGPF"
      },
      "outputs": [],
      "source": [
        "# TODO: for the students: which additional data explorations would you do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgNzthy_ZGPF"
      },
      "source": [
        "## Define the Base Model\n",
        "Here we build a DNN with 20 hidden layers of 100 neurons each.\n",
        "That's too many, but it's the point of this exercise, because it allows us to use some of the optimization techniques we learned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-yncOG_ZGPF"
      },
      "outputs": [],
      "source": [
        "# TODO: for the students: can you add comments to each line of code below explaining what it does and why?\n",
        "\n",
        "# ?\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# ?\n",
        "model = tf.keras.Sequential()\n",
        "# ?\n",
        "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "# ?\n",
        "for _ in range(20):\n",
        "    # ?\n",
        "    model.add(tf.keras.layers.Dense(100,\n",
        "                                    # ?\n",
        "                                    activation=\"swish\",\n",
        "                                    # ?\n",
        "                                    kernel_initializer=\"he_normal\"))\n",
        "# ?\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Ejr5_XZGPF"
      },
      "source": [
        "## Define the Loss Function, Optimizer and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDq1hsSBZGPF"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49EYyaLBZGPG"
      },
      "source": [
        "## Define Callbacks for Early Stopping, Checkpoints, and Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QjZGlidZGPG"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
        "                                                     restore_best_weights=True)\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cifar10_model\",\n",
        "                                                         save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = f\"./runs/cifar10_logs/run_{run_index:03d}\"\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0J6tDCHZGPG"
      },
      "source": [
        "## Traing the Model\n",
        "Before start running the training, initialize Tensorboard, such that you can view the training as it progresses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKUUfJkTZGPG",
        "outputId": "52a48837-730e-4dc7-cdfb-4005b77b2899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1402/1407 [============================>.] - ETA: 0s - loss: 4.2818 - accuracy: 0.1513"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 28s 15ms/step - loss: 4.2756 - accuracy: 0.1515 - val_loss: 2.1403 - val_accuracy: 0.2244\n",
            "Epoch 2/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 2.0810 - accuracy: 0.2313"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 2.0809 - accuracy: 0.2313 - val_loss: 1.9804 - val_accuracy: 0.2630\n",
            "Epoch 3/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.9533 - accuracy: 0.2763"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.9534 - accuracy: 0.2763 - val_loss: 1.8966 - val_accuracy: 0.2916\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 1.8783 - accuracy: 0.3088"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.8783 - accuracy: 0.3088 - val_loss: 1.8738 - val_accuracy: 0.3116\n",
            "Epoch 5/100\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 1.8249 - accuracy: 0.3340"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.8247 - accuracy: 0.3341 - val_loss: 1.8041 - val_accuracy: 0.3430\n",
            "Epoch 6/100\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 1.7816 - accuracy: 0.3508"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.7817 - accuracy: 0.3507 - val_loss: 1.7502 - val_accuracy: 0.3600\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 1.7318 - accuracy: 0.3694"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.7318 - accuracy: 0.3694 - val_loss: 1.7351 - val_accuracy: 0.3738\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 1.7002 - accuracy: 0.3855"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 15ms/step - loss: 1.7002 - accuracy: 0.3855 - val_loss: 1.7028 - val_accuracy: 0.3880\n",
            "Epoch 9/100\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 1.6715 - accuracy: 0.3944"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.6713 - accuracy: 0.3944 - val_loss: 1.6720 - val_accuracy: 0.3976\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6482 - accuracy: 0.4057 - val_loss: 1.6938 - val_accuracy: 0.3794\n",
            "Epoch 11/100\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 1.6274 - accuracy: 0.4125"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6271 - accuracy: 0.4126 - val_loss: 1.6652 - val_accuracy: 0.3930\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 1.6070 - accuracy: 0.4223"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6070 - accuracy: 0.4223 - val_loss: 1.6641 - val_accuracy: 0.4018\n",
            "Epoch 13/100\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 1.5832 - accuracy: 0.4306"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 24s 17ms/step - loss: 1.5832 - accuracy: 0.4306 - val_loss: 1.6276 - val_accuracy: 0.4132\n",
            "Epoch 14/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.5707 - accuracy: 0.4361"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5707 - accuracy: 0.4361 - val_loss: 1.5913 - val_accuracy: 0.4286\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5533 - accuracy: 0.4408 - val_loss: 1.5986 - val_accuracy: 0.4264\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5401 - accuracy: 0.4478 - val_loss: 1.6042 - val_accuracy: 0.4256\n",
            "Epoch 17/100\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.4525"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5269 - accuracy: 0.4526 - val_loss: 1.5791 - val_accuracy: 0.4338\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5127 - accuracy: 0.4584 - val_loss: 1.5860 - val_accuracy: 0.4356\n",
            "Epoch 19/100\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 1.5001 - accuracy: 0.4649"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 22s 15ms/step - loss: 1.4998 - accuracy: 0.4650 - val_loss: 1.5625 - val_accuracy: 0.4378\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4885 - accuracy: 0.4673 - val_loss: 1.6041 - val_accuracy: 0.4346\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4793 - accuracy: 0.4708 - val_loss: 1.5934 - val_accuracy: 0.4312\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4666 - accuracy: 0.4748 - val_loss: 1.5676 - val_accuracy: 0.4412\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4566 - accuracy: 0.4794 - val_loss: 1.5868 - val_accuracy: 0.4334\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4470 - accuracy: 0.4815 - val_loss: 1.5772 - val_accuracy: 0.4312\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 1.4372 - accuracy: 0.4861"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4372 - accuracy: 0.4861 - val_loss: 1.5530 - val_accuracy: 0.4470\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4283 - accuracy: 0.4871 - val_loss: 1.5633 - val_accuracy: 0.4374\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4163 - accuracy: 0.4945 - val_loss: 1.5593 - val_accuracy: 0.4486\n",
            "Epoch 28/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.4103 - accuracy: 0.4977"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4105 - accuracy: 0.4976 - val_loss: 1.5404 - val_accuracy: 0.4464\n",
            "Epoch 29/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.4002 - accuracy: 0.5010"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4003 - accuracy: 0.5010 - val_loss: 1.5354 - val_accuracy: 0.4590\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.3897 - accuracy: 0.5036 - val_loss: 1.5882 - val_accuracy: 0.4348\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3853 - accuracy: 0.5033 - val_loss: 1.5682 - val_accuracy: 0.4512\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3757 - accuracy: 0.5078 - val_loss: 1.5412 - val_accuracy: 0.4554\n",
            "Epoch 33/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.3706 - accuracy: 0.5082"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.3705 - accuracy: 0.5082 - val_loss: 1.5273 - val_accuracy: 0.4602\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3624 - accuracy: 0.5148 - val_loss: 1.5912 - val_accuracy: 0.4432\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3501 - accuracy: 0.5182 - val_loss: 1.5656 - val_accuracy: 0.4510\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3478 - accuracy: 0.5196 - val_loss: 1.5330 - val_accuracy: 0.4534\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3353 - accuracy: 0.5208 - val_loss: 1.5402 - val_accuracy: 0.4610\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3297 - accuracy: 0.5253 - val_loss: 1.5326 - val_accuracy: 0.4536\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3222 - accuracy: 0.5285 - val_loss: 1.5674 - val_accuracy: 0.4422\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3135 - accuracy: 0.5306 - val_loss: 1.5563 - val_accuracy: 0.4594\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3095 - accuracy: 0.5331 - val_loss: 1.5556 - val_accuracy: 0.4518\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3006 - accuracy: 0.5337 - val_loss: 1.5653 - val_accuracy: 0.4516\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2963 - accuracy: 0.5362 - val_loss: 1.5582 - val_accuracy: 0.4578\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2881 - accuracy: 0.5404 - val_loss: 1.5959 - val_accuracy: 0.4470\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2815 - accuracy: 0.5415 - val_loss: 1.5311 - val_accuracy: 0.4628\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2720 - accuracy: 0.5445 - val_loss: 1.5399 - val_accuracy: 0.4632\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2641 - accuracy: 0.5485 - val_loss: 1.5482 - val_accuracy: 0.4674\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2617 - accuracy: 0.5495 - val_loss: 1.5694 - val_accuracy: 0.4546\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2528 - accuracy: 0.5524 - val_loss: 1.5597 - val_accuracy: 0.4572\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2492 - accuracy: 0.5536 - val_loss: 1.5944 - val_accuracy: 0.4502\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2421 - accuracy: 0.5546 - val_loss: 1.6118 - val_accuracy: 0.4568\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2367 - accuracy: 0.5563 - val_loss: 1.5780 - val_accuracy: 0.4610\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2271 - accuracy: 0.5605 - val_loss: 1.5489 - val_accuracy: 0.4710\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x234b7c88a10>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZG2BUq4ZGPG"
      },
      "source": [
        "### Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FOAWYqhZGPG",
        "outputId": "6c9e17f3-1d1d-4888-84d5-7b44bedc1335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 2.0587 - accuracy: 0.2486"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 337s 30ms/step - loss: 2.0587 - accuracy: 0.2486 - val_loss: 1.9431 - val_accuracy: 0.3086\n",
            "Epoch 2/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.7941 - accuracy: 0.3535"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.7941 - accuracy: 0.3535 - val_loss: 1.8227 - val_accuracy: 0.3592\n",
            "Epoch 3/100\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 1.6840 - accuracy: 0.3973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 38s 27ms/step - loss: 1.6838 - accuracy: 0.3975 - val_loss: 1.7438 - val_accuracy: 0.3806\n",
            "Epoch 4/100\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 1.6111 - accuracy: 0.4237"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.6112 - accuracy: 0.4236 - val_loss: 1.6386 - val_accuracy: 0.4024\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 28s 20ms/step - loss: 1.5632 - accuracy: 0.4446 - val_loss: 1.6867 - val_accuracy: 0.3854\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 1.5128 - accuracy: 0.4652"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 54s 38ms/step - loss: 1.5128 - accuracy: 0.4652 - val_loss: 1.5506 - val_accuracy: 0.4396\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 38s 27ms/step - loss: 1.4671 - accuracy: 0.4799 - val_loss: 1.6614 - val_accuracy: 0.4240\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.4302 - accuracy: 0.4938 - val_loss: 1.5765 - val_accuracy: 0.4292\n",
            "Epoch 9/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.3954 - accuracy: 0.5093"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 78s 55ms/step - loss: 1.3954 - accuracy: 0.5093 - val_loss: 1.5060 - val_accuracy: 0.4656\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 42s 30ms/step - loss: 1.3621 - accuracy: 0.5171 - val_loss: 1.5754 - val_accuracy: 0.4382\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.3364 - accuracy: 0.5261 - val_loss: 1.5168 - val_accuracy: 0.4716\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.3023 - accuracy: 0.5420 - val_loss: 1.6920 - val_accuracy: 0.4122\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.2783 - accuracy: 0.5467 - val_loss: 1.5458 - val_accuracy: 0.4648\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 1.2533 - accuracy: 0.5555"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: cifar10_bn_model\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 68s 49ms/step - loss: 1.2533 - accuracy: 0.5555 - val_loss: 1.4674 - val_accuracy: 0.4842\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 49s 35ms/step - loss: 1.2316 - accuracy: 0.5633 - val_loss: 1.6214 - val_accuracy: 0.4560\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 49s 35ms/step - loss: 1.2135 - accuracy: 0.5704 - val_loss: 1.5224 - val_accuracy: 0.4748\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 48s 34ms/step - loss: 1.1919 - accuracy: 0.5789 - val_loss: 1.4811 - val_accuracy: 0.4776\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 49s 35ms/step - loss: 1.1708 - accuracy: 0.5856 - val_loss: 1.5899 - val_accuracy: 0.4480\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 49s 35ms/step - loss: 1.1602 - accuracy: 0.5932 - val_loss: 1.6210 - val_accuracy: 0.4552\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 47s 34ms/step - loss: 1.1358 - accuracy: 0.5994 - val_loss: 1.5326 - val_accuracy: 0.4750\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1186 - accuracy: 0.6045 - val_loss: 1.4992 - val_accuracy: 0.4864\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 45s 32ms/step - loss: 1.1049 - accuracy: 0.6080 - val_loss: 1.5002 - val_accuracy: 0.4794\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 1.0911 - accuracy: 0.6155 - val_loss: 1.5103 - val_accuracy: 0.4778\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 1.0784 - accuracy: 0.6182 - val_loss: 1.5375 - val_accuracy: 0.4770\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 1.0592 - accuracy: 0.6267 - val_loss: 1.5751 - val_accuracy: 0.4644\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 1.0506 - accuracy: 0.6290 - val_loss: 1.5140 - val_accuracy: 0.4792\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 45s 32ms/step - loss: 1.0294 - accuracy: 0.6362 - val_loss: 1.5457 - val_accuracy: 0.4864\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 45s 32ms/step - loss: 1.0239 - accuracy: 0.6363 - val_loss: 1.7156 - val_accuracy: 0.4638\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 44s 32ms/step - loss: 1.0152 - accuracy: 0.6408 - val_loss: 1.6811 - val_accuracy: 0.4548\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 1.0021 - accuracy: 0.6431 - val_loss: 1.5996 - val_accuracy: 0.4788\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 0.9910 - accuracy: 0.6488 - val_loss: 1.5630 - val_accuracy: 0.4858\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 0.9790 - accuracy: 0.6548 - val_loss: 1.7414 - val_accuracy: 0.4452\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 44s 32ms/step - loss: 0.9666 - accuracy: 0.6599 - val_loss: 1.5815 - val_accuracy: 0.4930\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 44s 31ms/step - loss: 0.9590 - accuracy: 0.6596 - val_loss: 1.6336 - val_accuracy: 0.4662\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 1.4674 - accuracy: 0.4842\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.4674395322799683, 0.48420000076293945]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
        "    model.add(tf.keras.layers.BatchNormalization())  # Adding batch normalization\n",
        "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
        "                                                     restore_best_weights=True)\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cifar10_bn_model\",\n",
        "                                                         save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = f\"cifar10_logs/run_bn_{run_index:03d}\"\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model.evaluate(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQUd7LiMZGPG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgQH3PixZGPH"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow_cpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}